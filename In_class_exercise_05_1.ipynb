{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "In_class_exercise_05-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinnaSaiVarun/saivarun_INFO5731_-Fall2021/blob/main/In_class_exercise_05_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9itMuZOMMPY"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVyNjAjUMMPa"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15uOWaSbMMPb"
      },
      "source": [
        "# Write your code here\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH2SMbZWMOLO"
      },
      "source": [
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "except ImportError ('Installing XGBoost...'):\n",
        "    !pip install xgboost"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-WPj-VaMOHw",
        "outputId": "5d00497e-c57e-474f-ae0a-350716e72891"
      },
      "source": [
        "data_train = pd.read_csv(r'/content/stsa-train.txt',sep = 'delimiter=',header= None,names=['review'])\n",
        "data_test = pd.read_csv(r'/content/stsa-test.txt',sep = 'delimiter=',header= None,names=['review'])\n",
        "\n",
        "data_train[['sentiment','review']] = data_train[\"review\"].str.split(\" \", 1, expand=True)\n",
        "data_test[['sentiment','review']] = data_test[\"review\"].str.split(\" \", 1, expand=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "AuNpbmquMOE1",
        "outputId": "1311c2fe-6c86-456b-c507-00368a31a506"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  a stirring , funny and finally transporting re...         1\n",
              "1  apparently reassembled from the cutting-room f...         0\n",
              "2  they presume their audience wo n't sit still f...         0\n",
              "3  this is a visually stunning rumination on love...         1\n",
              "4  jonathan parker 's bartleby should have been t...         1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "0QnrogKjMOCI",
        "outputId": "e2f3a8ee-1d1b-4370-f84e-de395f2280ee"
      },
      "source": [
        "data_test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0     no movement , no yuks , not much of anything .         0\n",
              "1  a gob of drivel so sickly sweet , even the eag...         0\n",
              "2  gangs of new york is an unapologetic mess , wh...         0\n",
              "3  we never really feel involved with the story ,...         0\n",
              "4            this is one of polanski 's best films .         1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uvDbQFxMN_D"
      },
      "source": [
        "with open('/content/stsa-train.txt') as fin:\n",
        "    data = fin.readlines()\n",
        "with open('/content/stsa-test.txt') as fin:\n",
        "    data.extend(fin.readlines())\n",
        "sentiment = [x[0] for x in data]\n",
        "review = [x.strip()[2:] for x in data]\n",
        "df = pd.DataFrame({'review' : review, 'sentiment': sentiment})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmcMVgyOMN8H"
      },
      "source": [
        "#TEXT PROCESSING"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy2H-nQvMN5V",
        "outputId": "112d8841-6ba1-4533-8709-8e695c7598dc"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6_2fdEYMN2k"
      },
      "source": [
        "\n",
        "def data_cleaning(data):\n",
        "  data=\"\".join([word.lower() for word in data if word not in string.punctuation])\n",
        "  data = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", data)\n",
        "  tokens = re.split('\\W+',data)\n",
        "  data = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "  return data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhOuHzfIMNzw",
        "outputId": "79216b1c-9f6a-49c8-9d40-a5dffd2f8320"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer = data_cleaning)\n",
        "X_tfidf = tfidf.fit_transform(data_train['review'])\n",
        "print(X_tfidf.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 13343)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "BZ7dVbbHMNw5",
        "outputId": "88659779-e31a-4b35-d7e4-ca184e188938"
      },
      "source": [
        "X_tfidf=pd.DataFrame(X_tfidf.toarray())\n",
        "X_tfidf.columns=tfidf.get_feature_names()\n",
        "X_tfidf.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>100minute</th>\n",
              "      <th>103minute</th>\n",
              "      <th>10course</th>\n",
              "      <th>10th</th>\n",
              "      <th>10thgrade</th>\n",
              "      <th>10year</th>\n",
              "      <th>10yearold</th>\n",
              "      <th>112minute</th>\n",
              "      <th>12</th>\n",
              "      <th>129minute</th>\n",
              "      <th>12th</th>\n",
              "      <th>12yearold</th>\n",
              "      <th>13th</th>\n",
              "      <th>14yearold</th>\n",
              "      <th>15th</th>\n",
              "      <th>15year</th>\n",
              "      <th>168minute</th>\n",
              "      <th>18yearold</th>\n",
              "      <th>1930s</th>\n",
              "      <th>1940s</th>\n",
              "      <th>1950s</th>\n",
              "      <th>1960s</th>\n",
              "      <th>1970s</th>\n",
              "      <th>1980s</th>\n",
              "      <th>19th</th>\n",
              "      <th>19thcentury</th>\n",
              "      <th>20car</th>\n",
              "      <th>20th</th>\n",
              "      <th>21st</th>\n",
              "      <th>22yearold</th>\n",
              "      <th>24andunders</th>\n",
              "      <th>26yearold</th>\n",
              "      <th>2day</th>\n",
              "      <th>30</th>\n",
              "      <th>34th</th>\n",
              "      <th>37minute</th>\n",
              "      <th>3d</th>\n",
              "      <th>3yearolds</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>yuen</th>\n",
              "      <th>yung</th>\n",
              "      <th>yvan</th>\n",
              "      <th>zaidan</th>\n",
              "      <th>zany</th>\n",
              "      <th>zap</th>\n",
              "      <th>zaza</th>\n",
              "      <th>zboys</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zeitgeist</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zellweger</th>\n",
              "      <th>zemeckis</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zerodimensional</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zhao</th>\n",
              "      <th>zhuangzhuang</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zing</th>\n",
              "      <th>zinger</th>\n",
              "      <th>zingerfilled</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipper</th>\n",
              "      <th>zippy</th>\n",
              "      <th>zishe</th>\n",
              "      <th>ziyi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombieland</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoning</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzz</th>\n",
              "      <th>élan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.048154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.029784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.049596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.048782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13343 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             100minute  103minute  10course  ...  zoom  zwick  zzzzzzzzz  élan\n",
              "0  0.000000        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "1  0.048154        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "2  0.029784        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "3  0.049596        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "4  0.048782        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "\n",
              "[5 rows x 13343 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnVXDHHTMNpy",
        "outputId": "46e8af58-9e4b-4b9d-c115-8a98a6b67786"
      },
      "source": [
        "test_tfidf = tfidf.transform(data_test['review'])\n",
        "print(test_tfidf.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1821, 13343)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z660EvtEMNcY"
      },
      "source": [
        "#splittind data into test and train data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf, data_train['sentiment'].values,\n",
        "                                                test_size=0.2, random_state=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g38vHwVzOugK"
      },
      "source": [
        "naive_bayes = MultinomialNB()\n",
        "svc = SVC()\n",
        "knn = KNeighborsClassifier()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier()\n",
        "algos = [naive_bayes, svc, knn, dt, rf, xgb]\n",
        "cut = ['nb', 'svc', 'knn', 'dt', 'rf', 'xgb']\n",
        "estimators = []\n",
        "for name, model in zip(cut, algos):\n",
        "    cv = Pipeline([('vect', CountVectorizer()), (name,model)])\n",
        "    estimators.append(cv)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSqz1PrnOuZb"
      },
      "source": [
        "model = naive_bayes.fit(x_train,y_train)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4GvUwqQOuWH"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q2U0GQEOuTj",
        "outputId": "42a1fc19-2353-4115-cc25-be4aaf17d1e0"
      },
      "source": [
        "# Accuracy using Multinomial algorithm\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(naive_bayes, x_test, y_test, cv=18)\n",
        "y_pred_naive_bayes = model.predict(x_test)\n",
        "print(\"The accuracy for Multinomial\",accuracy.mean())\n",
        "print('accuracy %s' % accuracy_score(y_pred_naive_bayes,y_test))\n",
        "print(classification_report(y_test,y_pred_naive_bayes))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for Multinomial 0.7210735171261488\n",
            "accuracy 0.7695086705202312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.69      0.74       675\n",
            "           1       0.74      0.85      0.79       709\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.78      0.77      0.77      1384\n",
            "weighted avg       0.77      0.77      0.77      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRZITHxDOuQ7"
      },
      "source": [
        "#Accuracy using decision tree\n",
        "model1= dt.fit(x_train,y_train)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRCSBdDtOuOP",
        "outputId": "03ec5f7d-2787-4ae7-b21e-c261a86edc09"
      },
      "source": [
        "y_pred_decision_tree = model1.predict(x_test)\n",
        "accuracy = cross_val_score(dt, x_test, y_test, cv=10)\n",
        "print('accuracy' % accuracy_score(y_pred_decision_tree,y_test))\n",
        "print(classification_report(y_test,y_pred_decision_tree))\n",
        "print(\"The accuracy for decision trees\",accuracy.mean())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.57      0.59       675\n",
            "           1       0.62      0.66      0.64       709\n",
            "\n",
            "    accuracy                           0.62      1384\n",
            "   macro avg       0.62      0.62      0.61      1384\n",
            "weighted avg       0.62      0.62      0.62      1384\n",
            "\n",
            "The accuracy for decision trees 0.5765926389323324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ingdo4eOuLt",
        "outputId": "ddc476dc-3230-405e-fd81-b28513e50da7"
      },
      "source": [
        "#accuracy using KNeighbours\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(knn, x_test, y_test, cv=10)\n",
        "model2 = knn.fit(x_train,y_train)\n",
        "y_pred_knn= model2.predict(x_test)\n",
        "print('accuracy' % accuracy_score(y_pred_knn,y_test))\n",
        "print(classification_report(y_test,y_pred_knn))\n",
        "print(\"The accuracy using knn\",accuracy.mean())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69       675\n",
            "           1       0.70      0.74      0.72       709\n",
            "\n",
            "    accuracy                           0.71      1384\n",
            "   macro avg       0.71      0.71      0.71      1384\n",
            "weighted avg       0.71      0.71      0.71      1384\n",
            "\n",
            "The accuracy using knn 0.6633041392972578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7svkaFYOuI1",
        "outputId": "b1cc6776-5533-4880-b8f2-c464061c0a3a"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(svc, x_test, y_test, cv=10)\n",
        "print(\"using svm\",accuracy.mean())\n",
        "model3 = svc.fit(x_train,y_train)\n",
        "y_pred_svc = model3.predict(x_test)\n",
        "print(' The accuracy using svc %s' % accuracy_score(y_pred_svc,y_test))\n",
        "print(classification_report(y_test,y_pred_svc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using svm 0.7066416432071734\n",
            " The accuracy using svc 0.7673410404624278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.74      0.76       675\n",
            "           1       0.76      0.80      0.78       709\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.77      0.77      0.77      1384\n",
            "weighted avg       0.77      0.77      0.77      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs3KStKnOuGL",
        "outputId": "d21e67ae-ec84-401f-8ec3-854a31aad722"
      },
      "source": [
        "#accuracy using random forest\n",
        "model4 = rf.fit(x_train,y_train)\n",
        "y_pred_rf = model4.predict(x_test)\n",
        "accuracy = cross_val_score(rf, x_test, y_test, cv=10)\n",
        "print('The accuracy using random forest' % accuracy_score(y_pred_rf,y_test))\n",
        "print(classification_report(y_test,y_pred_rf))\n",
        "print(\"using random forest\",accuracy.mean())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy using random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.63      0.67       675\n",
            "           1       0.68      0.75      0.71       709\n",
            "\n",
            "    accuracy                           0.69      1384\n",
            "   macro avg       0.69      0.69      0.69      1384\n",
            "weighted avg       0.69      0.69      0.69      1384\n",
            "\n",
            "using random forest 0.6611510791366906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-Md0duOOuDi",
        "outputId": "5044815a-e6fb-4df9-c9ef-37e7db5fc643"
      },
      "source": [
        "#accuracy using XG boost\n",
        "model_xgb = xgb.fit(x_train,y_train)\n",
        "y_pred_xgb = model_xgb.predict(x_test)\n",
        "accuracy = cross_val_score(xgb, x_test, y_test, cv=10)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_xgb,y_test))\n",
        "print(classification_report(y_test,y_pred_xgb))\n",
        "print(\"The accuracy using XG boost\",accuracy.mean())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.6213872832369942\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.37      0.49       675\n",
            "           1       0.59      0.86      0.70       709\n",
            "\n",
            "    accuracy                           0.62      1384\n",
            "   macro avg       0.65      0.62      0.59      1384\n",
            "weighted avg       0.65      0.62      0.60      1384\n",
            "\n",
            "The accuracy using XG boost 0.6206808466270461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neJHBwXLTUl1"
      },
      "source": [
        "From the above results we can see that Multinomial algoritham has best best accuracy and precision results.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHIK4L3HTUiM",
        "outputId": "12603a3a-8597-4b8a-af44-0061d4b471a5"
      },
      "source": [
        "#Evaluating test data\n",
        "\n",
        "test_data_naive_bayes = model.predict(X_tfidf)\n",
        "print('The accuracy on test data using Multinonial %s' % accuracy_score(test_data_naive_bayes,data_train['sentiment']))\n",
        "print(classification_report(test_data_naive_bayes,data_train['sentiment']))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data using Multinonial 0.9119942196531792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      3091\n",
            "           1       0.95      0.89      0.92      3829\n",
            "\n",
            "    accuracy                           0.91      6920\n",
            "   macro avg       0.91      0.91      0.91      6920\n",
            "weighted avg       0.91      0.91      0.91      6920\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_C50qkiMMPc"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "eI4seBXgMMPd",
        "outputId": "0271b93b-9981-48ef-e72d-bea25ac795c8"
      },
      "source": [
        "#Write your code here.\n",
        "import re\n",
        "import nltk\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
        "%matplotlib inline\n",
        "dataset = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "dataset.head()\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Product Name  ... Review Votes\n",
              "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          1.0\n",
              "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "712C1tTxc0-F",
        "outputId": "c6b6ec99-a363-4d8b-e8f6-0a6fd6f850af"
      },
      "source": [
        "print(f'Number of reviews {dataset.shape[0]}')\n",
        "dataset.isnull().sum()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews 236563\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Product Name        0\n",
              "Brand Name      34365\n",
              "Price            2829\n",
              "Rating              1\n",
              "Reviews            37\n",
              "Review Votes     7248\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ua0Z-3Kc06u",
        "outputId": "eb99b597-bd50-44d2-b021-9a45ca35a456"
      },
      "source": [
        "dataset['Reviews'].head()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    I feel so LUCKY to have found this used (phone...\n",
              "1    nice phone, nice up grade from my pantach revu...\n",
              "2                                         Very pleased\n",
              "3    It works good but it goes slow sometimes but i...\n",
              "4    Great phone to replace my lost phone. The only...\n",
              "Name: Reviews, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLzqrRWCc04I",
        "outputId": "95b88ab6-66fd-4356-fd24-efa8c87035f9"
      },
      "source": [
        "import re\n",
        "dataset['Reviews']=dataset['Reviews'].map(lambda x: re.sub('[?|!|\\'|\"|#]', '', str(x)))\n",
        "dataset['Reviews']=dataset['Reviews'].map(lambda x: x.lower())\n",
        "dataset['Reviews'].head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    i feel so lucky to have found this used (phone...\n",
              "1    nice phone, nice up grade from my pantach revu...\n",
              "2                                         very pleased\n",
              "3    it works good but it goes slow sometimes but i...\n",
              "4    great phone to replace my lost phone. the only...\n",
              "Name: Reviews, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DujSmtOuc01c"
      },
      "source": [
        "def tolist( review, remove_stopwords=True):\n",
        "    \n",
        "    text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
        "    words = text.lower().split()    \n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    x=[]\n",
        "    stemmer = english_stemmer \n",
        "    for word in words:\n",
        "        x.append(stemmer.stem(word))\n",
        "    return(x)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwCDoAkic0yh",
        "outputId": "ab7f170c-c88c-4626-af52-ed67827e932a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "clean_data_reviews = []\n",
        "for review in dataset['Reviews']:\n",
        "    clean_data_reviews.append( \" \".join(tolist(review)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9REIqSEc0vi",
        "outputId": "f4de41d9-298a-42fd-a560-d6f64bbc6a04"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "vectors = TfidfVectorizer(stop_words='english')\n",
        "S = vectors.fit_transform(clean_data_reviews)\n",
        "true_k = 10\n",
        "text = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
        "text.fit(S)\n",
        "\n",
        "print(\"most repeated words in cluster:\")\n",
        "order_centroids = text.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectors.get_feature_names()\n",
        "for i in range(true_k):\n",
        "    print(\"Cluster %d:\" % i),\n",
        "    for ind in order_centroids[i, :10]:\n",
        "        print(' %s' % terms[ind]),\n",
        "    print\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"analysis\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most repeated words in cluster:\n",
            "Cluster 0:\n",
            " good\n",
            " product\n",
            " like\n",
            " nice\n",
            " love\n",
            " iphon\n",
            " expect\n",
            " use\n",
            " phone\n",
            " watch\n",
            "Cluster 1:\n",
            " excel\n",
            " product\n",
            " phone\n",
            " thank\n",
            " recommend\n",
            " condit\n",
            " good\n",
            " seller\n",
            " price\n",
            " love\n",
            "Cluster 2:\n",
            " phone\n",
            " use\n",
            " great\n",
            " love\n",
            " good\n",
            " like\n",
            " batteri\n",
            " screen\n",
            " new\n",
            " price\n",
            "Cluster 3:\n",
            " excelent\n",
            " producto\n",
            " gracia\n",
            " recomendado\n",
            " telefono\n",
            " bueno\n",
            " celular\n",
            " muy\n",
            " product\n",
            " servicio\n",
            "Cluster 4:\n",
            " work\n",
            " phone\n",
            " great\n",
            " fine\n",
            " good\n",
            " new\n",
            " doesnt\n",
            " stop\n",
            " like\n",
            " perfect\n",
            "Cluster 5:\n",
            " fast\n",
            " ship\n",
            " great\n",
            " phone\n",
            " good\n",
            " deliveri\n",
            " product\n",
            " love\n",
            " price\n",
            " work\n",
            "Cluster 6:\n",
            " perfect\n",
            " work\n",
            " condit\n",
            " phone\n",
            " everyth\n",
            " thank\n",
            " new\n",
            " product\n",
            " great\n",
            " love\n",
            "Cluster 7:\n",
            " ok\n",
            " thank\n",
            " good\n",
            " everyth\n",
            " phone\n",
            " love\n",
            " great\n",
            " expect\n",
            " product\n",
            " work\n",
            "Cluster 8:\n",
            " great\n",
            " love\n",
            " phone\n",
            " work\n",
            " product\n",
            " price\n",
            " condit\n",
            " buy\n",
            " iphon\n",
            " deal\n",
            "Cluster 9:\n",
            " good\n",
            " phone\n",
            " product\n",
            " price\n",
            " far\n",
            " work\n",
            " qualiti\n",
            " deal\n",
            " realli\n",
            " buy\n",
            "\n",
            "\n",
            "analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpSzPtAoc0sn",
        "outputId": "39398b24-9121-4062-980f-b9a422b3e175"
      },
      "source": [
        "Y = vectors.transform([\"the phone works good\"])\n",
        "analysis = text.predict(Y)\n",
        "print(analysis)\n",
        "\n",
        "Y = vectors.transform([\"great phone to use\"])\n",
        "analysis = text.predict(Y)\n",
        "print(analysis)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n",
            "[8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGP_tMPnc0pt"
      },
      "source": [
        "DB SCAN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StUAHHlBc0ms"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr1ntSOcc0jy"
      },
      "source": [
        "Reviews_data=[]\n",
        "for t in dataset['Reviews']:\n",
        "  Reviews_data.append(t.split())\n",
        "import gensim\n",
        "w2v_model=gensim.models.Word2Vec(Reviews_data, size=10, workers=4)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ1Xe7Wdc0gl",
        "outputId": "8137f928-03f1-42a5-e12d-6f09de763c51"
      },
      "source": [
        "data_vectors = []\n",
        "for t in Reviews_data:\n",
        "    vector = np.zeros(100)\n",
        "    words = 0\n",
        "    for word in t:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            vector += vec\n",
        "            words += 1\n",
        "        except:\n",
        "            pass\n",
        "    vector /= words\n",
        "    data_vectors.append(vector)\n",
        "    \n",
        "data_vectors = np.array(data_vectors)\n",
        "data_vectors = np.nan_to_num(data_vectors)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcifSiBdc0dj"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "minPts = 2 * 100\n",
        "\n",
        "def lower_bound(nums, target): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    while l <= r: # Binary searching.\n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= target:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l\n",
        "def compute200thnearestneighbour(x, data): # Returns the distance of 200th nearest neighbour.\n",
        "    dists = []\n",
        "    for val in data:\n",
        "        dist = np.sum((x - val) **2 ) # computing distances.\n",
        "        if(len(dists) == 200 and dists[199] > dist): # If distance is larger than current largest distance found.\n",
        "            l = int(lower_bound(dists, dist)) # Using the lower bound function to get the right position.\n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "    \n",
        "    return dists[199]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRYpZ3Pye5qz",
        "outputId": "aaf5ef4f-53c9-411f-c371-01ebc0a72c4c"
      },
      "source": [
        "data_vectors.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(236563, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4uSv2Gse5kT"
      },
      "source": [
        "\n",
        "twohundrethneigh = []\n",
        "for val in data_vectors[:500]:\n",
        "    twohundrethneigh.append( compute200thnearestneighbour(val, data_vectors[:500]))\n",
        "twohundrethneigh.sort()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "l_CGtdoXfxVl",
        "outputId": "a6329797-4e60-41b2-c660-d518184a02a5"
      },
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
        "plt.plot([x for x in range(len(twohundrethneigh))], twohundrethneigh)\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAEWCAYAAAC+IKwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwlVX338c+XAQQFkWVE2RwEjMEkoGlQ1Cgqghq2+CBCQNCgRB9xNwGXKKIm4Epc86AoixuIIiAaQQRcYoQBUQRFcACHfRlkFZTh9/xR1XBpum/XzPTtvkN/3q/XfXXVqXOrfrfu6e77u+fUqVQVkiRJkqT+VpjpACRJkiRpeWDyJEmSJEkdmDxJkiRJUgcmT5IkSZLUgcmTJEmSJHVg8iRJkiRJHZg8SZpxSV6Z5Mc965Vk05mMaapM5WtJckWS7SbYtmqSU5LcmuTrU3G8CY6zV5LTlvK589rzsWK7/t0k+05thBMe++AkXxrg/v8ryb91rHtUkg8MKpap8nD6PZSkqWLyJGlatB/8/5jkjp7Hp2Y6Lrg/easkHx9TvktbflTH/ZyV5NUDCXJyuwHrAmtX1cuWdWdJtk1y35j365Sq+nJVbb/s4UJVvbiqjp6KffVqY79qqvfbT1W9tqrePxX7mixpadvr4jHvzR1J1puK42vqDDpplzT9VpzpACTNKjtV1fdnOogJ/A7YPcm/VNW9bdm+wG9nMKYl8QTgtz2xd5ZkxQmed01VbbDsoT28JZlTVYun+bA/rapnT/Mxp12ftjkU+xu05S1eaTaw50nSsHpJkgVJbkry4SQrACRZIcm7k1yZ5IYkxyRZo912dJK3tcvrt9/gv75d3yTJotH9jOM64EJgh7b+WsAzgZN7KyV5RpL/SfKHJL9Ism1b/kHg74BPjdOrtl2SS9vnfDpJJnst7fZXtNtuTvKuiU5UkvcB7wFe3h57v0nO0+jwuf2S/B74QZc3pH3ueEMsXzvB65uT5CPte7gA+Psx+7q/p250v239W5JcnuTFPXU3TvLDJLcn+X57nId8o5/kUcB3gfXG6ZFZuT0Ptye5KMlIz/PWS/KNJDe2x35jn3NwVJLPJvlOkjuB52XMULwk/5rk2iTXJHl1HtqbtGaSU9tYfpZkk/Z5P2y3/6KN/eWTvCXjxXdFknckubg9l19Mskq7bZ0k327fq0VJftTndwLGabtJVm6f+9c9x3xskruSzE3b85fkne17f0WSvXrqPqJ9n3+f5Po0Qx5XbbeNPvfAJNcBX+ywv79P8vMktyVZmOTgnm3jtvUkX09yXZphrj9M8pSe5xyV5DNphpXekeQnSR6X5PD2fP4myVN76o/bdpK8CHgnD/xe/qItXyPJkW37uDrJB5LMabe9sj3ex5PcDNz/WiQNB5MnScPqH4AR4GnALsA/teWvbB/PA54IrAaMJipnA9u2y88FFgDP6Vn/UVXd1+eYxwD7tMt7ACcB94xuTLI+cCrwAWAt4O3AN5LMrap3AT8CDqiq1arqgJ797ghsBfwNsDttgtbvtSTZHPgs8ApgPWBtYNxeoKp6L/DvwHHtsY+c5DyNei7wlz3xLK2JXt9r2m1PpXkvd5tkP08HLgHWAT4EHJk0iRjwFeAcmvNwMM15eYiquhN4MU2v2Wrt45p2887A14DH0CTFo+d6BeAU4BfA+sALgDcn6Xde/hH4ILA68OPeDe2H5rcC2wGb8kCb7LUH8D5gTeCydl9U1Wh73aKN/bg+MfSzF837sAnwJODdbfnbgKuAuTTDPN8JVJ/9POS9rao/0ZzHvXvq7QmcUVU3tuuPo3kf16fpwT0iyV+02w5tY9qS5vysT5P80/PctWh6U/fvsL87aX5vH0OToL8uya5jXsfYtv5dYDPgscD5wJfH1N+d5pytQ/M34KdtvXWAE4CPQf+2U1X/zYN/L7do930UcG/72p8KbA/0Dvd9Os3frnVp24Wk4WHyJGk6fav9Bnv08Zo+dQ+rqkVV9XvgcJoPZ9B8KPxYVS2oqjuAdwB7pJmE4Gzg2e0HmufQfAB/Vvu857bb+zkR2DZND80+NMlUr72B71TVd6rqvqo6HZgPvGSS/R5aVX9oX8uZNB8aJ3stuwHfrqofVtU9wL8B/RK/sfrte9TBVXVnVf1xgn2sN+b92n0JX9/uwOFVtbCqFgH/MUnMV1bV59ohcEcDjwfWTbIRzQf491TVn6rqx4zpEezox+17txg4Fhj9MLsVMLeqDmn3vwD4HE2CM5GTquonbTu4e8y23YEvVtVFVXUX4/cenFhV57RDsr7MA+esq2eMeW9+N2b7p3rO+wd54PfnzzTn9QlV9eeq+lFV9UueJnpvjwb27EluX0FzTnv9W1XdU1Vn03zpsHtbf3/gLe3v9+00CUbvub4PeG/73D/22x9AVZ1VVRe278Uvga/S/L73elBbr6ovVNXt7e/WwcAW6en1pXl/zmvf2xOBu6vqmLbtHEeT9MAStp0k69L8vXhzG88NwMfH1L+mqj5ZVff2+d2UNEO85knSdNp1Ca55WtizfCVN7wvtzyvHbFsRWLeqfpdmGNWWNEPo3g/s135D/VzgE/0OWFV/THIqzTfOa1fVT9IzdIzmm/CXJdmpp2wlmg+V/VzXs3wXTS9Q39fSbrv/HFTVne0wnq767XvUQvp7yDVPSV45Tr1+r2/s+9jP/fupqrvaz+Wr0Xzbv6hNREYtBDacZH+TxblKm0w+gTZR7Nk+h6YncSL9zt16NEl1v7oTnbOu/neSa54m+v35ME2ycFp7fo+oqkP77GfcOKvqZ0nuovmy4VqaXpTehPaWthdwbAxzgUcC5z2QdxGa8z3qxnES0on2R5Kn0/Rm/RWwMvAIYOyMk/efj3aI3AeBl7XxjH4psQ5wa7t8fc9z/zjO+uj7taRt5wk0fzOu7Xn9K/Dg92uy30tJM8jkSdKw2hC4qF3eCBgdenUNzQcQerbdywMfbs6m6bVZuaquTnI2zTCfNYELOhz3GJrrIt43zraFwLFVNVGPWb9v8MfT77VcSzPMCIAkj6QZsjYV+x5NiJY03iV1LQ9OcDZahv2sleSRPQlUv8RpSV/XQuDyqtpsCZ7T7xjX8uAhlkua5E2Fsef9GoC2p+dtwNuS/BXwgyTnVtUZS3GMo2l6Y68DThiT8KyZ5FE9Cc9GwK+Am2iSj6dU1dUT7He8czvR/qAZ0vkp4MVVdXeSw2kSoYn2+Y80Q4G3A64A1gBuoUniltRkbWfsa1lIMwxwnT4TQQz691LSMnDYnqRh9S9J1kyyIfAmmqEy0AzJeUuaCQRW44FrCkY/iJwNHACMXnh/Vrv+4+o2I9rZwAuBT46z7UvATkl2SDMZwirtxeyjH5Svp7m+qKt+r+UEYMckz06yMnAIS/Y3e7LzNB2OB96YZIMkawIHLc1OqupKmp6cg9NMVrANsFOfp1wPrD1mGFY/5wC3p5mkYNX2vf2rJFstTbw0r/tVSf6yTXo73f+px5K2o/G8vj3vawHvov39SbJjkk3b4XO3AotZsuGgvb5Ec23i3jx0iCvA+9r36+9orp36ejXXHH4O+HiSx7YxrT/J9WUT7q8tX52mZ/LuJFvTJEf9rE6TwNxM0wv27x2OPZHJ2s71wLx2KDFVdS1wGvDRJI9OM7HLJknGDjOUNKRMniRNp1Py4PvSnNin7knAeTS9RacCR7blX6C5tuKHwOXA3cAbep53Ns2Ho9Hk6cc0H5B+SAfVOKO9VmTstoU031i/E7iR5lvkf+GBv6X/CeyWZkauvkMEJ3stVXUR8Hqab9WvpflmfEnuXTTZeZoOnwO+R3Mx/fnAN5dhX3sB29B84P0ATTJwz3gVq+o3NMnjgvZ6oL73P2qT6h1phnteTtM78nmaHoklVlXfpRkieibNZBD/224aN95xHAwcPcl1Ztvkofd56k32vkLzIX0BzTT8ozMBbgZ8H7iDZhKEz1TVZMNOx9X+PpxP01MydpjadTRt9hqaa7pe274vAAfSnpckt7Xx/AX99dvf/wUOSXI7zcQTx0+yr2Nohv1dDVzMA+/PEuvQdkYTvJuTnN8u70MzvPDi9jWdQHMdmqTlQPpfJypJ0vBJchzwm2pmGhxqSf6SZojZI6aj5y/JFcCrl+D6wmU51hdoro17d0/ZtsCXxl4vtwzHmNL9SdKysOdJkjT0kmzVDm9aIc1U4LsA35rpuCaS5B/S3M9oTeAw4JRpHjI5cEnmAS/lgV5hSXrYM3mSJC0PHkdz/dodNEPiXldVP5/RiPr7Z+AGmiFzi4HXzWw4UyvJ+2l60z5cVZfPdDySNF0ctidJkiRJHdjzJEmSJEkdzKr7PK2zzjo1b968mQ5DkiRJ0pA677zzbqqqueNtm1XJ07x585g/f/7kFSVJkiTNSkmunGibw/YkSZIkqQOTJ0mSJEnqwORJkiRJkjoweZIkSZKkDkyeJEmSJKkDkydJkiRJ6sDkSZIkSZI6MHmSJEmSpA5MniRJkiSpA5MnSZIkSerA5EmSJEmSOjB5kiRJkqQOTJ4kSZIkqQOTJ0mSJEnqwORJkiRJkjoweZIkSZKkDvomT0nmJPnNdAUjSZIkScOqb/JUVYuBS5JsNE3xSJIkSdJQWrFDnTWBi5KcA9w5WlhVOw8sKkmSJEkaMl2Sp38beBSSJEmSNOQmTZ6q6uzpCESSJEmShtmkyVOS24FqV1cGVgLurKpHDzIwSZIkSRomXXqeVh9dThJgF+AZgwxKkiRJkobNEt3nqRrfAnYYUDySJEmSNJS6DNt7ac/qCsAIcPfAIpIkSZKkIdSl52mnnscOwO00Q/eWWZIXJbkkyWVJDhpn+yOSHNdu/1mSeWO2b5TkjiRvn4p4JEmSJGkiXa55etUgDpxkDvBp4IXAVcC5SU6uqot7qu0H3FJVmybZAzgMeHnP9o8B3x1EfJIkSZLUa9KepyQbJDkxyQ3t4xtJNpiCY28NXFZVC6rqT8DXeGiP1i7A0e3yCcAL2kkrSLIrcDlw0RTEIkmSJEl9dRm290XgZGC99nFKW7as1gcW9qxf1ZaNW6eq7gVuBdZOshpwIPC+yQ6SZP8k85PMv/HGG6cgbEmSJEmzUZfkaW5VfbGq7m0fRwFzBxzXZA4GPl5Vd0xWsaqOqKqRqhqZO3emw5YkSZK0vJr0mifg5iR7A19t1/cEbp6CY18NbNizvkFbNl6dq5KsCKzRHvvpwG5JPgQ8Brgvyd1V9akpiEuSJEmSHqJL8vRPwCeBj7frPwGmYhKJc4HNkmxMkyTtAfzjmDonA/sCPwV2A35QVQX83WiFJAcDd5g4SZIkSRqkLrPtXQnsPNUHrqp7kxwAfA+YA3yhqi5Kcggwv6pOBo4Ejk1yGbCIJsGSJEmSpGmXpiOnT4XkicB/As8AiqYX6C1VtWDw4U2tkZGRmj9//kyHIUmSJGlIJTmvqkbG29ZlwoivAMcDj6eZbe/rPHD9kyRJkiTNCl2Sp0dW1bE9s+19CVhl0IFJkiRJ0jCZ8JqnJGu1i99NchDNTWwLeDnwnWmITZIkSZKGRr8JI86jSZbSrv9zz7YC3jGooCRJkiRp2EyYPFXVxtMZiCRJkiQNsy73eSLJM4F5vfWr6pgBxSRJkiRJQ2fS5CnJscAmwAXA4ra4AJMnSZIkSbNGl56nEWDzmuyGUJIkSZL0MNZlqvJfAY8bdCCSJEmSNMz6TVV+Cs3wvNWBi5OcA9wzur2qdh58eJIkSZI0HPoN2/vItEUhSZIkSUOu31TlZ09nIJIkSZI0zLrMtnc7zfC9XrcC84G3VdWCQQQmSZIkScOky2x7hwNXAV8BAuxBM3X5+cAXgG0HFZwkSZIkDYsus+3tXFX/r6pur6rbquoIYIeqOg5Yc8DxSZIkSdJQ6JI83ZVk9yQrtI/dgbvbbd77SZIkSdKs0CV52gt4BXADcH27vHeSVYEDBhibJEmSJA2NSa95aieE2GmCzT+e2nAkSZIkaTj1u0nuv1bVh5J8knGG51XVGwcamSRJkiQNkX49T79uf86fjkAkSZIkaZj1u0nuKe3PowGSPLKq7pquwCRJkiRpmEw6YUSSbZJcDPymXd8iyWcGHpkkSZIkDZEus+0dDuwA3AxQVb8AnjPIoCRJkiRp2HRJnqiqhWOKFg8gFkmSJEkaWpNOVQ4sTPJMoJKsBLyJByaTkCRJkqRZoUvP02uB1wPrA1cDW7brkiRJkjRrdLlJ7k3AXtMQiyRJkiQNrX43yX1Pn+dVVb1/APFIkiRJ0lDq1/N05zhljwL2A9YGTJ4kSZIkzRr9bpL70dHlJKvTTBTxKuBrwEcnep4kSZIkPRz1nTAiyVpJPgD8kibRelpVHVhVN0zFwZO8KMklSS5LctA42x+R5Lh2+8+SzGvLX5jkvCQXtj+fPxXxSJIkSdJEJkyeknwYOBe4Hfjrqjq4qm6ZqgMnmQN8GngxsDmwZ5LNx1TbD7ilqjYFPg4c1pbfBOxUVX8N7AscO1VxSZIkSdJ4+vU8vQ1YD3g3cE2S29rH7Ulum4Jjbw1cVlULqupPNMMBdxlTZxfg6Hb5BOAFSVJVP6+qa9ryi4BVkzxiCmKSJEmSpHH1u+apyz2glsX6wMKe9auAp09Up6ruTXIrzWQVN/XU+T/A+VV1zwBjlSRJkjTLTXqfp2GW5Ck0Q/m271Nnf2B/gI022miaIpMkSZL0cDPo3qV+rgY27FnfoC0bt06SFYE1gJvb9Q2AE4F9qup3Ex2kqo6oqpGqGpk7d+4Uhi9JkiRpNpnJ5OlcYLMkGydZGdgDOHlMnZNpJoQA2A34QVVVkscApwIHVdVPpi1iSZIkSbPWpMlTksO6lC2pqroXOAD4HvBr4PiquijJIUl2bqsdCayd5DLgrcDodOYHAJsC70lyQft47LLGJEmSJEkTSVX1r5CcX1VPG1P2y6r6m4FGNgAjIyM1f/78mQ5DkiRJ0pBKcl5VjYy3bcIJI5K8Dvi/wBOT/LJn0+qAQ+UkSZIkzSr9Ztv7CvBd4D94YLgcwO1VtWigUUmSJEnSkJnwmqequrWqrqC5Se51VXUlsDGwdzthgyRJkiTNGl1m2/sGsDjJpsARNFOHf2WgUUmSJEnSkOmSPN3Xzoz3UuCTVfUvwOMHG5YkSZIkDZcuydOfk+wJ7AN8uy1baXAhSZIkSdLw6ZI8vQrYBvhgVV2eZGPg2MGGJUmSJEnDpd9sewBU1cVJDgQ2atcvB5b5JrmSJEmStDyZtOcpyU7ABcB/t+tbJjl50IFJkiRJ0jDpMmzvYGBr4A8AVXUB8MQBxiRJkiRJQ6fThBFVdeuYsvsGEYwkSZIkDatJr3kCLkryj8CcJJsBbwT+Z7BhSZIkSdJw6dLz9AbgKcA9NDfHvRV48yCDkiRJkqRh07fnKckc4NSqeh7wrukJSZIkSZKGT9+ep6paDNyXZI1pikeSJEmShlKXa57uAC5Mcjpw52hhVb1xYFFJkiRJ0pDpkjx9s31IkiRJ0qw1afJUVUdPRyCSJEmSNMwmTZ7a6cn/A9gcWGW0vKq8Ua4kSZKkWaPLVOVfBD4L3As8DzgG+NIgg5IkSZKkYdMleVq1qs4AUlVXVtXBwN8PNixJkiRJGi5dJoy4J8kKwKVJDgCuBlYbbFiSJEmSNFy69Dy9CXgk8Ebgb4G9gX0HGZQkSZIkDZsus+2dC5Dkvqp61eBDkiRJkqThM2nPU5JtklwM/KZd3yLJZwYemSRJkiQNkS7D9g4HdgBuBqiqXwDPGWRQkiRJkjRsuiRPVNXCMUWLBxCLJEmSJA2tLrPtLUzyTKCSrEQzgcSvBxuWJEmSJA2XLj1PrwVeD6xPM035lu26JEmSJM0aXWbbuwnYaxpikSRJkqShNWHylOQ9fZ5XVfX+AcQjSZIkSUOp37C9O8d5AOwHHDgVB0/yoiSXJLksyUHjbH9EkuPa7T9LMq9n2zva8kuS7DAV8UiSJEnSRCbseaqqj44uJ1mdZqKIVwFfAz460fO6SjIH+DTwQuAq4NwkJ1fVxT3V9gNuqapNk+wBHAa8PMnmwB7AU4D1gO8neVJVOQugJEmSpIHoe81TkrWAt9Jc83Q08LSqumWKjr01cFlVLWiP9TVgF6A3edoFOLhdPgH4VJK05V+rqnuAy5Nc1u7vp1MU20C975SLuPia22Y6DEmSJGnGbb7eo3nvTk+Z6TA6mXDYXpIPA+cCtwN/XVUHT2HiBM3sfb33j7qqLRu3TlXdC9wKrN3xuQAk2T/J/CTzb7zxxikKXZIkSdJs06/n6W3APcC7gXc1HT4AhGbCiEcPOLYpUVVHAEcAjIyM1AyHA7DcZNaSJEmSHtDvmqcu94BaFlcDG/asb9CWjVfnqiQrAmsAN3d8riRJkiRNmUEnSP2cC2yWZOMkK9NMAHHymDonA/u2y7sBP6iqasv3aGfj2xjYDDhnmuKWJEmSNAtNepPcQamqe5McAHwPmAN8oaouSnIIML+qTgaOBI5tJ4RYRJNg0dY7nmZyiXuB1zvTniRJkqRBStORMzuMjIzU/PnzZzoMSZIkSUMqyXlVNTLetpkctidJkiRJy41Jk6ckL01yaZJbk9yW5PYk3qRIkiRJ0qzS5ZqnDwE7VdWvBx2MJEmSJA2rLsP2rjdxkiRJkjTbTdjzlOSl7eL8JMcB36K5aS4AVfXNAccmSZIkSUOj37C9nXqW7wK271kvwORJkiRJ0qwxYfJUVa8CSPKsqvpJ77Ykzxp0YJIkSZI0TLpc8/TJjmWSJEmS9LDV75qnbYBnAnOTvLVn06OBOYMOTJIkSZKGSb9rnlYGVmvrrN5Tfhuw2yCDkiRJkqRh0++ap7OBs5N8sap+P40xSZIkSdLQmfCapyRrJDkUOC3JoiQ3J/l1kkOTPGYaY5QkSZKkGddvwojjgVuAbatqrapaG3ge8Id2myRJkiTNGv2Sp3lVdVhVXTdaUFXXVdWhwBMGH5okSZIkDY9+ydOVSf41ybqjBUnWTXIgsHDwoUmSJEnS8OiXPL0cWJtm0ohbktwCnAWsBew+DbFJkiRJ0tDoN9veLcCB7UOSJEmSZrV+93kiyQ7ArsD6bdHVwElV9d+DDkySJEmShsmEyVOSw4EnAccAV7XFGwBvTPLiqnrTNMQnSZIkSUOhX8/TS6rqSWMLkxwH/BYweZIkSZI0a/SbMOLuJFuNU74VcPeA4pEkSZKkodSv5+mVwGeTrM4Dw/Y2BG5tt0mSJEnSrNFvtr3zgacneRw9E0b03jRXkiRJkmaLvrPttW4emzAlWaeqbhpQTJIkSZI0dCa85inJ85JcBVyb5LQk83o2nzbowCRJkiRpmPSbMOJDwA5VtQ5wBHB6kme02zLwyCRJkiRpiPQbtrdyVV0EUFUnJPk18M0kBwI1LdFJkiRJ0pDolzz9OcnjRq93qqqLkrwA+DawybREJ0mSJElDot+wvYOAdXsLquoq4LnAoYMMSpIkSZKGTb+pyr8/QfmtwAcHFpEkSZIkDaF+PU8Dk2StJKcnubT9ueYE9fZt61yaZN+27JFJTk3ymyQXJbEXTJIkSdLAzUjyRDMk8Iyq2gw4o11/kCRrAe8Fng5sDby3J8n6SFU9GXgq8KwkL56esCVJkiTNVv3u83Rs+/NNAzjuLsDR7fLRwK7j1NkBOL2qFlXVLcDpwIuq6q6qOhOgqv4EnA9sMIAYJUmSJOl+/Xqe/jbJesA/JVmzHWp3/2MZj7tuVV3bLl/HmIkpWusDC3vWr2rL7pfkMcBONL1XkiRJkjQw/aYq/y+apOSJwHk8+Ma41ZZPKMn3gceNs+ldvStVVUmW+L5RSVYEvgp8oqoW9Km3P7A/wEYbbbSkh5EkSZIkoP9se58APpHks1X1uiXdcVVtN9G2JNcneXxVXZvk8cAN41S7Gti2Z30D4Kye9SOAS6vq8EniOKKty8jIiDf3lSRJkrRUJp0woqpel2SLJAe0j7+ZguOeDOzbLu8LnDROne8B27dDBtcEtm/LSPIBYA3gzVMQiyRJkiRNatLkKckbgS8Dj20fX07yhmU87qHAC5NcCmzXrpNkJMnnAapqEfB+4Nz2cUhVLUqyAc3Qv82B85NckOTVyxiPJEmSJPWVqv4j2ZL8Etimqu5s1x8F/LSqpqIHalqNjIzU/PnzZzoMSZIkSUMqyXlVNTLeti73eQqwuGd9MQ+ePEKSJEmSHvb6zbY36ovAz5Kc2K7vChw5uJAkSZIkafhMmjxV1ceSnAU8uy16VVX9fKBRSZIkSdKQ6dLzRFWdD5w/4FgkSZIkaWh1ueZJkiRJkmY9kydJkiRJ6qBT8pTkCUm2a5dXTbL6YMOSJEmSpOHS5Sa5rwFOAP5fW7QB8K1BBiVJkiRJw6ZLz9PrgWcBtwFU1aXAYwcZlCRJkiQNmy7J0z1V9afRlSQrAjW4kCRJkiRp+HRJns5O8k5g1SQvBL4OnDLYsCRJkiRpuHRJng4CbgQuBP4Z+A7w7kEGJUmSJEnDpstNclcFvlBVnwNIMqctu2uQgUmSJEnSMOnS83QGTbI0alXg+4MJR5IkSZKGU5fkaZWqumN0pV1+5OBCkiRJkqTh0yV5ujPJ00ZXkvwt8MfBhSRJkiRJw6fLNU9vBr6e5BogwOOAlw80KkmSJEkaMpMmT1V1bpInA3/RFl1SVX8ebFiSJEmSNFy69DwBbAXMa+s/LQlVdczAopIkSZKkITNp8pTkWGAT4AJgcVtcgMmTJEmSpFmjS8/TCLB5VdWgg5EkSZKkYdVltr1f0UwSIUmSJEmzVpeep3WAi5OcA9wzWlhVOw8sKkmSJEkaMl2Sp4MHHYQkSZIkDbsuU5WfPR2BSJIkSdIwm/SapyTPSHJukjuS/CnJ4iS3TUdwkiRJkjQsukwY8SlgT+BSYFXg1cCnBxmUJEmSJA2bLskTVXUZMKeqFlfVF4EXDTYsSZIkSRouXSaMuCvJysAFST4EXEvHpEuSJEmSHi66JEGvaOsdANwJbAi8dJBBSZIkSdKw6ZI87VpVd1fVbVX1vqp6K7DjoAOTJEmSpGHSJXnad5yyVy7LQZOsleT0JJe2P9ecoN6+bZ1LkzwkjiQnJ/nVssQiSZIkSV1MmDwl2TPJKcDGbZ9+Dt0AAAroSURBVJIy+jgLWLSMxz0IOKOqNgPOaNfHHn8t4L3A04Gtgff2JllJXgrcsYxxSJIkSVIn/SaM+B+aySHWAT7aU3478MtlPO4uwLbt8tHAWcCBY+rsAJxeVYsAkpxOM8vfV5OsBrwV2B84fhljkSRJkqRJTZg8VdWVwJVJtgP+WFX3JXkS8GTgwmU87rpVdW27fB2w7jh11gcW9qxf1ZYBvJ8mobtrsgMl2Z8myWKjjTZa2nglSZIkzXJdrnn6IbBKkvWB02hm3ztqsicl+X6SX43z2KW3XlUVUF0DTrIlsElVndilflUdUVUjVTUyd+7croeRJEmSpAfpcp+nVNVdSfYDPlNVH0pywWRPqqrtJtxhcn2Sx1fVtUkeD9wwTrWreWBoH8AGNMP7tgFGklzRxv/YJGdV1bZIkiRJ0oB06XlKkm2AvYBT27I5y3jck3lgFr99gZPGqfM9YPska7YTRWwPfK+qPltV61XVPODZwG9NnCRJkiQNWpfk6c3AO4ATq+qiJE8EzlzG4x4KvDDJpcB27TpJRpJ8HqCdKOL9wLnt45DRySMkSZIkabqlueRodhgZGan58+fPdBiSJEmShlSS86pqZLxtE17zlOTwqnpze6+nh2RYVbXzFMYoSZIkSUOt34QRx7Y/PzIdgUiSJEnSMOt3n6fz2p9nJ5nbLt84XYFJkiRJ0jDpO2FEkoOT3ARcAvw2yY1J3jM9oUmSJEnS8JgweUryVuBZwFZVtVZVrQk8HXhWkrdMV4CSJEmSNAz69Ty9Atizqi4fLaiqBcDewD6DDkySJEmShkm/5GmlqrppbGF73dNKgwtJkiRJkoZPv+TpT0u5TZIkSZIedvpNVb5FktvGKQ+wyoDikSRJkqSh1G+q8jnTGYgkSZIkDbO+U5VLkiRJkhomT5IkSZLUgcmTJEmSJHVg8iRJkiRJHZg8SZIkSVIHJk+SJEmS1IHJkyRJkiR1YPIkSZIkSR2YPEmSJElSByZPkiRJktSByZMkSZIkdWDyJEmSJEkdmDxJkiRJUgcmT5IkSZLUQapqpmOYNkluBK6c6Tha6wA3zXQQWi7ZdrQ0bDdaGrYbLQ3bjZbWsLSdJ1TV3PE2zKrkaZgkmV9VIzMdh5Y/th0tDduNlobtRkvDdqOltTy0HYftSZIkSVIHJk+SJEmS1IHJ08w5YqYD0HLLtqOlYbvR0rDdaGnYbrS0hr7teM2TJEmSJHVgz5MkSZIkdWDyJEmSJEkdmDzNgCQvSnJJksuSHDTT8Wh4JPlCkhuS/KqnbK0kpye5tP25ZlueJJ9o29Evkzxt5iLXTEqyYZIzk1yc5KIkb2rLbTvqK8kqSc5J8ou27byvLd84yc/aNnJckpXb8ke065e12+fNZPyaWUnmJPl5km+367Yb9ZXkiiQXJrkgyfy2bLn6X2XyNM2SzAE+DbwY2BzYM8nmMxuVhshRwIvGlB0EnFFVmwFntOvQtKHN2sf+wGenKUYNn3uBt1XV5sAzgNe3f1dsO5rMPcDzq2oLYEvgRUmeARwGfLyqNgVuAfZr6+8H3NKWf7ytp9nrTcCve9ZtN+rieVW1Zc/9nJar/1UmT9Nva+CyqlpQVX8CvgbsMsMxaUhU1Q+BRWOKdwGObpePBnbtKT+mGv8LPCbJ46cnUg2Tqrq2qs5vl2+n+TCzPrYdTaJtA3e0qyu1jwKeD5zQlo9tO6Nt6gTgBUkyTeFqiCTZAPh74PPterDdaOksV/+rTJ6m3/rAwp71q9oyaSLrVtW17fJ1wLrtsm1JD9EOh3kq8DNsO+qgHXp1AXADcDrwO+APVXVvW6W3fdzfdtrttwJrT2/EGhKHA/8K3Neur43tRpMr4LQk5yXZvy1brv5XrTjTAUjqrqoqifcX0LiSrAZ8A3hzVd3W+8WubUcTqarFwJZJHgOcCDx5hkPSkEuyI3BDVZ2XZNuZjkfLlWdX1dVJHgucnuQ3vRuXh/9V9jxNv6uBDXvWN2jLpIlcP9pN3f68oS23Lel+SVaiSZy+XFXfbIttO+qsqv4AnAlsQzM8ZvQL1t72cX/babevAdw8zaFq5j0L2DnJFTSXHzwf+E9sN5pEVV3d/ryB5suarVnO/leZPE2/c4HN2hlpVgb2AE6e4Zg03E4G9m2X9wVO6infp52N5hnArT3d3ppF2msHjgR+XVUf69lk21FfSea2PU4kWRV4Ic01c2cCu7XVxrad0Ta1G/CDqhrqb4k19arqHVW1QVXNo/kc84Oq2gvbjfpI8qgkq48uA9sDv2I5+18V2+70S/ISmrHCc4AvVNUHZzgkDYkkXwW2BdYBrgfeC3wLOB7YCLgS2L2qFrUfmD9FMzvfXcCrqmr+TMStmZXk2cCPgAt54PqDd9Jc92Tb0YSS/A3NBdpzaL5QPb6qDknyRJoehbWAnwN7V9U9SVYBjqW5rm4RsEdVLZiZ6DUM2mF7b6+qHW036qdtHye2qysCX6mqDyZZm+Xof5XJkyRJkiR14LA9SZIkSerA5EmSJEmSOjB5kiRJkqQOTJ4kSZIkqQOTJ0mSJEnqwORJkjTlklSSj/asvz3JwVO076OS7DZ5zWU+zsuS/DrJmVOwr++M3k+pT51XJllvWY8lSRockydJ0iDcA7w0yTozHUivJCsuQfX9gNdU1fOW9bhV9ZKq+sMk1V4JmDxJ0hAzeZIkDcK9wBHAW8ZuGNtzlOSO9ue2Sc5OclKSBUkOTbJXknOSXJhkk57dbJdkfpLfJtmxff6cJB9Ocm6SXyb55579/ijJycDF48SzZ7v/XyU5rC17D/Bs4MgkHx5Tf9skP0xyapJLkvxXkhUm2ldbfkWSdZLMa3uzPpfkoiSnJVm1PR8jwJeTXNCWHZrk4va1fGTp3gZJ0lRakm/gJElaEp8GfpnkQ0vwnC2AvwQWAQuAz1fV1kneBLwBeHNbbx6wNbAJcGaSTYF9gFuraqskjwB+kuS0tv7TgL+qqst7D9YOkzsM+FvgFuC0JLtW1SFJng+8fYI72m8NbA5cCfw3TS/b/0ywr2+Nee5mwJ5V9ZokxwP/p6q+lOSA0eMlWRv4B+DJVVWTDfmTJE0Pe54kSQNRVbcBxwBvXIKnnVtV11bVPcDvgNHk50KahGnU8VV1X1VdSpNkPRnYHtgnyQXAz4C1aRIVgHPGJk6trYCzqurGqroX+DLwnA5xnlNVC6pqMfBVml6qrvu6vKouaJfPG/O6Rt0K3E3T8/VS4K4OMUmSBszkSZI0SIfTXDv0qJ6ye2n//7TD3Vbu2XZPz/J9Pev38eDREjXmOAUEeENVbdk+Nq6q0eTrzmV6FQ813vG76n2NixlnFEibfG0NnADsSNO7JUmaYSZPkqSBqapFwPE0CdSoK2iGtgHsDKy0FLt+WZIV2uugnghcAnwPeF2SlQCSPCnJo/rtBDgHeG57PdIcYE/g7A7H3zrJxm3y93Lgx8uwr1G3A6u3sa8GrFFV36G5bmyLJdiPJGlAvOZJkjRoHwUO6Fn/HHBSkl/Q9KgsTa/Q72mSlUcDr62qu5N8nmYI3PlJAtwI7NpvJ1V1bZKDgDNpeq5OraqTOhz/XOBTwKbtc0+sqvuWcl+jjgL+K8kfgRfTnKNV2n29dQn2I0kakFQtyUgDSZJmtyTb0kzssONMxyJJml4O25MkSZKkDux5kiRJkqQO7HmSJEmSpA5MniRJkiSpA5MnSZIkSerA5EmSJEmSOjB5kiRJkqQO/j/TC9wV+Wg5XgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi1DY-jaMMPd"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgVgHLimMMPd"
      },
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "## K-means is a clustering algorithm that uses centroid based or partion based clustering. The algorithm divides the sample \n",
        "space into K groups based on their similarity. The euclidian distance is used to access similarity.DBScan is a clustering algorithm depends\n",
        "on density. The main feature of this algorithm is that each point is acluster must have minimum number of neighbours\n",
        "within a given radius.The alogorithm is shown to be very effective at identifying outliers and noises.Hierarchial\n",
        "clustering is a algorithm that divides objects into clusters based on their similarity.The endpoint is a set of clusters, \n",
        "each of which is distinct from others while articrafts within cluster are broadly identified.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}